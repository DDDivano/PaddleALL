grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
I0802 03:36:36.707141  9332 nccl_context.cc:120] init nccl context nranks: 8 local rank: 3 gpu id: 3
W0802 03:36:40.629251  9332 device_context.cc:259] Please NOTE: device: 3, CUDA Capability: 61, Driver API Version: 10.1, Runtime API Version: 9.0
W0802 03:36:40.640218  9332 device_context.cc:267] device: 3, cuDNN Version: 7.2.
W0802 03:36:40.640280  9332 device_context.cc:293] WARNING: device: 3. The installed Paddle is compiled with CUDNN 7.3, but CUDNN version in your machine is 7.2, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.

start data reader (trainers_num: 8, trainer_id: 3)
start data reader (trainers_num: 8, trainer_id: 3)
epoch: [0][ 1/13]	Time  2.098 ( 2.098)	Data  0.161 ( 0.161)
pass num : 0, batch_id: 1, dy_graph avg loss: [1.1553254]
epoch: [0][ 2/13]	Time  1.562 ( 1.830)	Data  0.048 ( 0.104)
pass num : 0, batch_id: 2, dy_graph avg loss: [1.153152]
epoch: [0][ 3/13]	Time  1.284 ( 1.648)	Data  0.048 ( 0.085)
pass num : 0, batch_id: 3, dy_graph avg loss: [1.1510248]
epoch: [0][ 4/13]	Time  1.300 ( 1.561)	Data  0.050 ( 0.077)
pass num : 0, batch_id: 4, dy_graph avg loss: [1.147602]
epoch: [0][ 5/13]	Time  1.427 ( 1.534)	Data  0.048 ( 0.071)
pass num : 0, batch_id: 5, dy_graph avg loss: [1.1455296]
epoch: [0][ 6/13]	Time  1.274 ( 1.491)	Data  0.048 ( 0.067)
pass num : 0, batch_id: 6, dy_graph avg loss: [1.1434813]
epoch: [0][ 7/13]	Time  1.577 ( 1.503)	Data  0.059 ( 0.066)
pass num : 0, batch_id: 7, dy_graph avg loss: [1.140593]
epoch: [0][ 8/13]	Time  1.277 ( 1.475)	Data  0.052 ( 0.064)
pass num : 0, batch_id: 8, dy_graph avg loss: [1.135324]
epoch: [0][ 9/13]	Time  1.609 ( 1.490)	Data  0.115 ( 0.070)
pass num : 0, batch_id: 9, dy_graph avg loss: [1.1350849]
epoch: [0][10/13]	Time  1.236 ( 1.465)	Data  0.050 ( 0.068)
pass num : 0, batch_id: 10, dy_graph avg loss: [1.1337237]
epoch: [0][11/13]	Time  1.369 ( 1.456)	Data  0.052 ( 0.066)
pass num : 0, batch_id: 11, dy_graph avg loss: [1.1313947]
epoch: [0][12/13]	Time  1.383 ( 1.450)	Data  0.052 ( 0.065)
pass num : 0, batch_id: 12, dy_graph avg loss: [1.1291655]
Traceback (most recent call last):
  File "train.py", line 1182, in <module>
    train()
  File "train.py", line 1165, in train
    transformer.apply_collective_grads()
  File "/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/parallel.py", line 186, in apply_collective_grads
    collective._allreduce(g_var, g_var, sync_mode=True)
  File "/usr/local/lib/python3.6/site-packages/paddle/fluid/layers/collective.py", line 48, in _allreduce
    "sync_mode": sync_mode})
  File "/usr/local/lib/python3.6/site-packages/paddle/fluid/layer_helper.py", line 43, in append_op
    return self.main_program.current_block().append_op(*args, **kwargs)
  File "/usr/local/lib/python3.6/site-packages/paddle/fluid/framework.py", line 1762, in append_op
    kwargs.get("stop_gradient", False))
  File "/usr/local/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py", line 59, in trace_op
    framework._current_expected_place(), stop_gradient)
KeyboardInterrupt
